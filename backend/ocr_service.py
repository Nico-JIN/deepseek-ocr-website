import torch
import os
from transformers import AutoModel, AutoTokenizer
from pathlib import Path
from typing import Optional, Dict, Callable, Awaitable
from threading import Event
import fitz  # PyMuPDF
from PIL import Image
import io
import asyncio

class OCRService:
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.model_name = 'D:\\models\\deepseek-ocr\\'
        self._ready = False
        
    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            print(torch.__version__)
            print(torch.cuda.device_count())  # æ˜¾ç¤ºå¯è§ GPU æ•°é‡
            print(torch.cuda.is_available())  # æ˜¯å¦æ£€æµ‹åˆ° GPU
            print("Loading DeepSeek-OCR model...")
            os.environ["CUDA_VISIBLE_DEVICES"] = '0'
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name, 
                trust_remote_code=True
            )
            # å‡å°‘ç”Ÿæˆè­¦å‘Šï¼šè‹¥æ—  pad_tokenï¼Œåˆ™ç”¨ eos å…œåº•
            try:
                if getattr(self.tokenizer, 'pad_token_id', None) is None and getattr(self.tokenizer, 'eos_token', None) is not None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                    print(f"Set tokenizer.pad_token to eos_token: id={self.tokenizer.pad_token_id}")
            except Exception as _:
                pass
            
            self.model = AutoModel.from_pretrained(
                self.model_name,
                _attn_implementation='flash_attention_2',
                trust_remote_code=True,
                use_safetensors=True
            )
            
            self.model = self.model.eval().cuda().to(torch.bfloat16)
            self._ready = True
            print("Model loaded successfully!")
            
        except Exception as e:
            print(f"Error loading model: {e}")
            raise
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        return self._ready
    
    def _get_stream_path(self, out_dir: str) -> str:
        """è¿”å›ç”¨äºå¢é‡å†™å…¥çš„ç»“æœæ–‡ä»¶è·¯å¾„ï¼Œé¿å…ä¸æ¨¡å‹è‡ªå¸¦ä¿å­˜å†²çªã€‚"""
        os.makedirs(out_dir, exist_ok=True)
        return os.path.join(out_dir, "result_stream.md")

    def _append_stream(self, out_dir: str, text: str, header: str = "") -> None:
        """å°†å†…å®¹è¿½åŠ å†™å…¥æµå¼ç»“æœæ–‡ä»¶ã€‚"""
        try:
            path = self._get_stream_path(out_dir)
            with open(path, "a", encoding="utf-8", errors="ignore") as f:
                if header:
                    f.write(header + "\n")
                f.write(text or "")
                f.write("\n\n")
                f.flush()
        except Exception:
            pass

    def _wait_for_file(self, file_path: str, timeout: float = 5.0, interval: float = 0.1) -> bool:
        """ç­‰å¾…æ–‡ä»¶åœ¨æŒ‡å®šæ—¶é—´å†…ç”Ÿæˆï¼Œè¿”å›æ˜¯å¦æˆåŠŸæ£€æµ‹åˆ°æ–‡ä»¶ã€‚"""
        import time

        if not file_path:
            return False

        elapsed = 0.0
        while elapsed < timeout:
            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                return True
            time.sleep(interval)
            elapsed += interval
        return os.path.exists(file_path) and os.path.getsize(file_path) > 0

    def _get_prompt(self, output_format: str, custom_prompt: Optional[str] = None) -> str:
        """è·å–æç¤ºè¯"""
        fmt = (output_format or "").strip().lower()

        # rec æ¨¡å¼ç‰¹æ®Šå¤„ç†ï¼šéœ€è¦ä» custom_prompt ä¸­æå–å®šä½ç›®æ ‡
        if fmt == "rec":
            if custom_prompt and custom_prompt.strip():
                target = custom_prompt.strip()
                prompt = f"<image>\nLocate <|ref|>{target}<|/ref|> in the image."
                print(f"ğŸ¯ Using rec prompt with target: {target}")
                return prompt
            raise ValueError("rec æ¨¡å¼éœ€è¦æŒ‡å®šå®šä½ç›®æ ‡ï¼ˆcustom_promptä¸èƒ½ä¸ºç©ºï¼‰")

        # å…¶ä»–æ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯
        if custom_prompt and custom_prompt.strip():
            print(f"ğŸ¯ Using custom prompt: {custom_prompt}")
            return custom_prompt

        default_prompts = {
            "markdown": "<image>\n<|grounding|>Convert the document to markdown.",
            "ocr": "<image>\n<|grounding|>OCR this image.",
            "free_ocr": "<image>\nFree OCR.",
            "figure": "<image>\nParse the figure.",
            "general": "<image>\nDescribe this image in detail.",
        }

        prompt = default_prompts.get(fmt)
        if prompt:
            print(f"ğŸ¯ Using default prompt for {fmt}: {prompt[:60]}...")
            return prompt

        raise ValueError(f"æœªçŸ¥çš„è¾“å‡ºæ ¼å¼ï¼š{output_format}")
    
    def _get_mode_params(self, mode: str) -> Dict:
        """è·å–æ¨¡å¼å‚æ•°"""
        modes = {
            "tiny": {"base_size": 512, "image_size": 512, "crop_mode": False},
            "small": {"base_size": 640, "image_size": 640, "crop_mode": False},
            "base": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
            "large": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
            "gundam": {"base_size": 1024, "image_size": 640, "crop_mode": True}
        }
        
        return modes.get(mode, modes["base"])

    def _read_fallback_output(self, out_dir: str) -> str:
        """å½“ model.infer è¿”å› None æ—¶ï¼Œå°è¯•ä»è¾“å‡ºç›®å½•è¯»å–ç»“æœæ–‡ä»¶ã€‚"""
        try:
            print(f"ğŸ“‚ Reading fallback from: {out_dir}")
            candidates = []
            preferred = {"result.mmd", "result.md", "result.txt"}
            
            # å…ˆæ£€æŸ¥å¸¸è§æ–‡ä»¶å
            for name in preferred:
                p = os.path.join(out_dir, name)
                if self._wait_for_file(p, timeout=6.0):
                    size = os.path.getsize(p)
                    print(f"  ğŸ” Found {name}, size: {size} bytes")
                    if size > 0:
                        with open(p, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                            print(f"  âœ… Read {len(content)} chars from {name}")
                            print(f"  ğŸ“„ Preview: {content[:200]}...")
                            return content
            
            # å…œåº•ï¼šæœç´¢ç›®å½•ä¸‹æ‰€æœ‰æ–‡æœ¬ç»“æœ
            print(f"  ğŸ” Searching all .mmd/.md/.txt files in {out_dir}")
            import time as time_module
            time_module.sleep(0.2)
            for root, _, files in os.walk(out_dir):
                for fn in files:
                    if fn.lower().endswith((".mmd", ".md", ".txt")):
                        fp = os.path.join(root, fn)
                        try:
                            if not self._wait_for_file(fp, timeout=2.0):
                                continue
                            size = os.path.getsize(fp)
                            mtime = os.path.getmtime(fp)
                            print(f"    Found: {fn} ({size} bytes)")
                            if size > 0:
                                candidates.append((mtime, fp))
                        except Exception:
                            continue
            
            if candidates:
                candidates.sort(reverse=True)
                _, fp = candidates[0]
                print(f"  âœ… Using most recent file: {os.path.basename(fp)}")
                with open(fp, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    print(f"  ğŸ“„ Read {len(content)} chars")
                    print(f"  ğŸ“„ Preview: {content[:200]}...")
                    return content
            else:
                print(f"  âš ï¸  No fallback files found")
        except Exception as e:
            print(f"  âŒ Fallback read error: {e}")
            pass
        return ""

    def _post_save_outputs(self, out_dir: str, text: str, output_format: str = "") -> None:
        """åœ¨è¾“å‡ºç›®å½•ä¸­ä¿å­˜ç»“æœæ–‡ä»¶ï¼šè‹¥åŒ…å« mermaid åˆ™ç”Ÿæˆ result.mmdï¼Œå¦åˆ™ä¿å­˜ä¸º result.mdã€‚
        recæ¨¡å¼è·³è¿‡ä¿å­˜ï¼Œå› ä¸ºåªéœ€è¦å›¾ç‰‡ã€‚"""
        try:
            # recæ¨¡å¼ä¸éœ€è¦ä¿å­˜æ–‡æœ¬ç»“æœï¼Œåªéœ€è¦result_with_boxes.jpg
            if output_format == "rec":
                print(f"ğŸ¯ recæ¨¡å¼ï¼šè·³è¿‡æ–‡æœ¬æ–‡ä»¶ä¿å­˜ï¼Œåªä¾èµ–å›¾ç‰‡")
                return
            
            os.makedirs(out_dir, exist_ok=True)
            content = text or ""
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–å ä½ç¬¦
            if not content.strip() or "[OCRè¿”å›ä¸ºç©º" in content:
                print(f"âš ï¸  å†…å®¹ä¸ºç©ºæˆ–é”™è¯¯å ä½ç¬¦ï¼Œè·³è¿‡ä¿å­˜")
                return
            
            has_mermaid = ("```mermaid" in content) or content.strip().startswith("graph ") or content.strip().startswith("flowchart ")
            if has_mermaid:
                mmd_path = os.path.join(out_dir, "result.mmd")
                with open(mmd_path, "w", encoding="utf-8", errors="ignore") as f:
                    if "```mermaid" not in content:
                        f.write("```mermaid\n" + content.strip() + "\n```")
                    else:
                        f.write(content)
                print(f"âœ… ä¿å­˜ mermaid ç»“æœåˆ°: {mmd_path}")
            else:
                md_path = os.path.join(out_dir, "result.md")
                with open(md_path, "w", encoding="utf-8", errors="ignore") as f:
                    f.write(content)
                print(f"âœ… ä¿å­˜ markdown ç»“æœåˆ°: {md_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            pass
    
    def _pdf_to_images(self, pdf_path: str, output_dir: str) -> list:
        """å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨"""
        try:
            pdf_document = fitz.open(pdf_path)
            image_paths = []
            
            print(f"PDF has {len(pdf_document)} page(s)")
            
            for page_num in range(len(pdf_document)):
                page = pdf_document[page_num]
                # ä½¿ç”¨è¾ƒé«˜çš„DPIä»¥è·å¾—æ›´å¥½çš„è´¨é‡
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom = 144 DPI
                
                img_path = os.path.join(output_dir, f"page_{page_num + 1}.png")
                pix.save(img_path)
                image_paths.append(img_path)
                print(f"Converted PDF page {page_num + 1} to {img_path}")
            
            pdf_document.close()
            return image_paths
            
        except Exception as e:
            raise RuntimeError(f"PDF conversion failed: {str(e)}")
    
    async def process(
        self,
        file_path: str,
        mode: str,
        output_format: str,
        custom_prompt: Optional[str] = None,
        output_path: str = "",
        on_progress: Optional[Callable[[Dict], Awaitable[None]]] = None,
        cancel_event: Optional[asyncio.Event] = None,
        thread_cancel_event: Optional[Event] = None
    ) -> Dict:
        """å¤„ç†OCRè¯·æ±‚"""
        if not self._ready:
            raise RuntimeError("Model is not ready")
        
        prompt = self._get_prompt(output_format, custom_prompt)
        mode_params = self._get_mode_params(mode)
        collected_image_paths = []
        
        try:
            def _check_cancel():
                if cancel_event is not None and cancel_event.is_set():
                    print("â›” Cancellation requested inside OCR process")
                    raise asyncio.CancelledError()

            _check_cancel()
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(file_path):
                raise RuntimeError(f"File not found: {file_path}")
            
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                raise RuntimeError(f"File is empty: {file_path}")
            
            # æ£€æµ‹æ–‡ä»¶ç±»å‹
            file_ext = os.path.splitext(file_path)[1].lower()
            print(f"Processing OCR with mode={mode}, format={output_format}")
            print(f"File: {file_path} ({file_size} bytes)")
            print(f"File type: {file_ext}")
            print(f"Mode params: {mode_params}")
            
            # å¤„ç† PDF æ–‡ä»¶
            if file_ext == '.pdf':
                print("PDF file detected, converting to images...")
                pdf_images_dir = os.path.join(output_path, "pdf_pages")
                os.makedirs(pdf_images_dir, exist_ok=True)
                os.makedirs(output_path, exist_ok=True)
                
                image_paths = self._pdf_to_images(file_path, pdf_images_dir)
                
                # å¤„ç†æ¯ä¸€é¡µ
                all_results = []
                # åˆå§‹åŒ–/æ¸…ç©ºæµå¼ç»“æœæ–‡ä»¶
                try:
                    open(self._get_stream_path(output_path), "w", encoding="utf-8", errors="ignore").close()
                except Exception:
                    pass
                
                # åˆ›å»ºçº¿ç¨‹æ± ç”¨äºåŒæ­¥æ¨ç†
                import asyncio
                import concurrent.futures
                loop = asyncio.get_event_loop()
                executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)
                try:
                    for idx, img_path in enumerate(image_paths):
                        _check_cancel()
                        print(f"\nProcessing page {idx + 1}/{len(image_paths)}...")
                        print(f"Prompt: {prompt[:100]}...")
                        
                        # ä¸ºæ¯ä¸€é¡µåˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
                        page_output_dir = os.path.join(output_path, f"page_{idx + 1}")
                        os.makedirs(page_output_dir, exist_ok=True)
                        
                        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥æ¨ç†ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                        def sync_infer():
                            return self.model.infer(
                                self.tokenizer,
                                prompt=prompt,
                                image_file=img_path,
                                output_path=page_output_dir,
                                base_size=mode_params["base_size"],
                                image_size=mode_params["image_size"],
                                crop_mode=mode_params["crop_mode"],
                                save_results=True,
                                test_compress=False,
                                cancel_event=thread_cancel_event
                            )
                        
                        print(f"â³ Starting async inference for page {idx + 1}...")
                        try:
                            result = await loop.run_in_executor(executor, sync_infer)
                        except asyncio.CancelledError:
                            raise
                        except RuntimeError as infer_error:
                            if "inference_cancelled" in str(infer_error).lower():
                                raise asyncio.CancelledError()
                            raise
                        print(f"â³ Inference completed for page {idx + 1}")
                    
                        print(f"ğŸ“‹ Page {idx + 1} infer result type: {type(result)}")
                        print(f"ğŸ“‹ Page {idx + 1} infer result: {result}")
                        
                        # è½¬æ¢ç»“æœä¸ºå­—ç¬¦ä¸²
                        if result is None:
                            # æ¨¡å‹è¿”å›Noneæ—¶ï¼Œå°è¯•ä»ä¿å­˜çš„æ–‡ä»¶è¯»å–
                            print(f"âš ï¸  Page {idx + 1}: Model returned None, trying fallback read...")
                            fallback_text = self._read_fallback_output(page_output_dir)
                            if fallback_text and fallback_text.strip():
                                page_text = fallback_text
                                print(f"âœ… Page {idx + 1}: Fallback read success, {len(page_text)} chars")
                            else:
                                page_text = "[OCRè¿”å›ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å›¾ç‰‡è´¨é‡æˆ–prompt]"
                                print(f"âŒ Page {idx + 1}: Model returned None and no saved file found")
                        elif isinstance(result, (list, tuple)):
                            page_text = str(result[0]) if result else ""
                            print(f"âœ… Page {idx + 1}: Got result from list/tuple, {len(page_text)} chars")
                        elif isinstance(result, dict):
                            page_text = str(result.get('text', result))
                            print(f"âœ… Page {idx + 1}: Got result from dict, {len(page_text)} chars")
                        else:
                            page_text = str(result)
                            print(f"âœ… Page {idx + 1}: Got result as string, {len(page_text)} chars")
                        
                        print(f"ğŸ“ Page {idx + 1} text length: {len(page_text)} chars")
                        all_results.append(f"--- Page {idx + 1} ---\n{page_text}")

                        # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦æ¡†å›¾ç‰‡ï¼ˆç­‰å¾…å†™å…¥å®Œæˆï¼‰
                        result_with_boxes = os.path.join(page_output_dir, "result_with_boxes.jpg")
                        has_image = self._wait_for_file(result_with_boxes, timeout=6.0)

                        image_path = None
                        if has_image:
                            collected_image_paths.append(result_with_boxes)
                            image_path = result_with_boxes
                            print(f"âœ… Page {idx + 1} result_with_boxes.jpg found")
                        else:
                            # å³ä½¿å›¾ç‰‡ä¸å­˜åœ¨ï¼Œä¹Ÿç»§ç»­å¤„ç†ï¼Œä¸å½±å“æ–‡æœ¬ç»“æœ
                            print(f"âš ï¸  Page {idx + 1} result_with_boxes.jpg NOT found after waiting, continuing...")

                        # è¾¹è§£æè¾¹ä¿å­˜ä¸è¾“å‡º
                        self._append_stream(output_path, page_text, header=f"--- Page {idx + 1} ---")
                        try:
                            print(f"\n[Stream] Page {idx + 1} output (first 200 chars):\n{page_text[:200]}\n")
                        except Exception:
                            pass

                        # å³æ—¶å‘ä¸Šå±‚å›è°ƒï¼Œé©±åŠ¨å‰ç«¯å®æ—¶æ˜¾ç¤º
                        print(f"ğŸš€ Sending page {idx + 1} to frontend via callback...")
                        if on_progress is not None:
                            try:
                                await on_progress({
                                    "type": "page",
                                    "page": idx + 1,
                                    "total": len(image_paths),
                                    "text": page_text,
                                    "image_path": image_path
                                })
                                print(f"âœ… Page {idx + 1} callback completed")
                                # é‡è¦ï¼šè®©å‡ºæ§åˆ¶æƒç»™äº‹ä»¶å¾ªç¯ï¼Œç¡®ä¿SSEç«‹å³å‘é€
                                import asyncio
                                await asyncio.sleep(0.1)
                            except Exception as e:
                                print(f"âŒ Page {idx + 1} callback failed: {e}")
                                pass
                        _check_cancel()
                        
                        # ä¸åˆ é™¤ä¸´æ—¶å›¾ç‰‡ï¼Œä¿ç•™ç”¨äºé¢„è§ˆ
                        # æ³¨é‡Šæ‰ï¼šos.remove(img_path)
                finally:
                    executor.shutdown(wait=False)
                
                _check_cancel()

                # åˆå¹¶æ‰€æœ‰é¡µé¢ç»“æœ
                final_result = "\n\n".join(all_results)
                # å¦‚æœæ¯é¡µå‡ä¸ºç©ºå ä½ï¼Œå°è¯•æ•´ä½“å›é€€è¯»å–ä¸€æ¬¡
                if not final_result.strip() or all('[OCRè¿”å›ä¸ºç©º' in r for r in all_results):
                    fb_all = self._read_fallback_output(output_path)
                    if fb_all.strip():
                        final_result = fb_all
                print(f"\nProcessed {len(image_paths)} pages successfully")
                _check_cancel()
                if not (output_format == "rec" and final_result == ""):
                    try:
                        self._post_save_outputs(output_path, final_result, output_format)
                    except Exception:
                        pass
                
            else:
                # å¤„ç†å›¾ç‰‡æ–‡ä»¶
                try:
                    with Image.open(file_path) as test_img:
                        test_img.verify()
                    with Image.open(file_path) as test_img:
                        _ = test_img.convert("RGB")
                    print(f"PIL image validation: OK")
                except Exception as pil_error:
                    raise RuntimeError(f"Invalid image file: {pil_error}")
                
                print(f"\nğŸ” Starting image OCR inference...")
                print(f"  Full Prompt: {prompt}")
                print(f"  Image file: {file_path}")
                print(f"  Output path: {output_path}")
                print(f"  Base size: {mode_params['base_size']}")
                print(f"  Image size: {mode_params['image_size']}")
                print(f"  Crop mode: {mode_params['crop_mode']}")
                os.makedirs(output_path, exist_ok=True)
                
                _check_cancel()

                try:
                    result = self.model.infer(
                        self.tokenizer,
                        prompt=prompt,
                        image_file=file_path,
                        output_path=output_path,
                        base_size=mode_params["base_size"],
                        image_size=mode_params["image_size"],
                        crop_mode=mode_params["crop_mode"],
                        save_results=True,
                        test_compress=False,
                        cancel_event=thread_cancel_event
                    )
                except RuntimeError as infer_error:
                    if "inference_cancelled" in str(infer_error).lower():
                        raise asyncio.CancelledError()
                    raise
                
                print(f"ğŸ” Inference completed!")
                _check_cancel()
                
                print(f"\nğŸ“‹ Raw infer result:")
                print(f"  Type: {type(result)}")
                print(f"  Content: {result}")
                print(f"  Preview (first 500 chars): {str(result)[:500]}...")
                
                # ç¡®ä¿ result æ˜¯å­—ç¬¦ä¸²ç±»å‹
                if result is None:
                    if output_format == "rec":
                        print("âš ï¸  Model returned None but rec mode only needs image; skipping fallback text read")
                        final_result = ""
                    else:
                        fallback_text = self._read_fallback_output(output_path)
                        final_result = fallback_text if fallback_text.strip() else "[OCRè¿”å›ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å›¾ç‰‡è´¨é‡æˆ–prompt]"
                        print(f"âš ï¸  Model returned None!")
                elif isinstance(result, (list, tuple)):
                    final_result = str(result[0]) if result else ""
                    print(f"âœ… Converted from list/tuple, length: {len(final_result)}")
                elif isinstance(result, dict):
                    final_result = str(result.get('text', result))
                    print(f"âœ… Converted from dict, length: {len(final_result)}")
                else:
                    final_result = str(result)
                    print(f"âœ… Converted to string, length: {len(final_result)}")
                
                print(f"\nâœ¨ Final result length: {len(final_result)} characters")
                print(f"âœ¨ Final result preview (first 200 chars): {final_result[:200]}...")
                # ç«‹å³å†™å…¥æµå¼ç»“æœæ–‡ä»¶
                self._append_stream(output_path, final_result, header="--- Image Result ---")

                # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦æ¡†å›¾ç‰‡
                result_with_boxes = os.path.join(output_path, "result_with_boxes.jpg")
                image_path = result_with_boxes if self._wait_for_file(result_with_boxes, timeout=6.0) else None
                if image_path:
                    collected_image_paths.append(image_path)
                    print(f"âœ… result_with_boxes.jpg found for single image")
                    if output_format == "rec" and final_result == "":
                        print("ğŸ¯ recæ¨¡å¼ï¼šä»…è¿”å›æ ‡æ³¨å›¾ï¼Œæ— éœ€æ–‡æœ¬")

                # å•å›¾ä¹Ÿå‘ä¸Šå±‚å›è°ƒä¸€æ¬¡ï¼Œä¾¿äºç»Ÿä¸€å‰ç«¯é€»è¾‘
                if on_progress is not None:
                    try:
                        print(f"ğŸ“¤ Sending image callback to frontend, image_path: {image_path}")
                        await on_progress({
                            "type": "image",
                            "text": final_result,
                            "image_path": image_path
                        })
                        print(f"âœ… Image callback sent successfully")
                    except Exception as e:
                        print(f"âŒ Image callback failed: {e}")
                        pass
                # å¼ºåˆ¶ä¿å­˜è¾“å‡ºï¼Œç¡®ä¿ç”Ÿæˆ .mmd/.md æ–‡ä»¶
                try:
                    self._post_save_outputs(output_path, final_result, output_format)
                except Exception:
                    pass
            
            return {
                "text": final_result,
                "prompt": prompt,
                "image_paths": collected_image_paths
            }   
            
        except asyncio.CancelledError:
            print("OCR processing cancelled by user")
            raise
        except Exception as e:
            print(f"OCR processing error: {type(e).__name__}: {str(e)}")
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"OCR processing failed: {type(e).__name__}: {str(e)}")
